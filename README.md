# üìÑ Desafio: Machine Learning (Entrega **14/10/2025 ‚Üí 21/11/2025**)
---

## üéØ Objetivo
Aplicar conceitos de **Machine Learning** e/ou **Refor√ßo (RL)** em um projeto pr√°tico.

---

## Regras
- Tema livre, **desde que** use ML/RL (ex.: MDPs, Q-Learning, SARSA, supervis./n√£o‚Äësupervis., etc.).
- Entrega deve incluir:
  - **C√≥digo-fonte** completo.
  - **README.md** com: ideia, mudan√ßas, como treinar/testar, bibliotecas, algoritmos, **c√°lculos**, dificuldades, **resultados com m√©tricas/gr√°ficos**.
- **Visual obrigat√≥rio**: gr√°ficos/tabelas/prints mostrando evolu√ß√£o/treinamento/resultados.
- Pode ser pequeno. **Foco: racioc√≠nio aplicado de ML.**

---

## üìö Conte√∫do m√≠nimo
- Trade-off **explora√ß√£o vs. aproveitamento** (exploration vs. exploitation).
- **Atualiza√ß√£o din√¢mica** de aprendizado (Q-Table ou equivalente).
- **Ajuste da taxa de explora√ß√£o** (ex.: *epsilon decay*).
- **Recompensa e penalidade** (design de *reward*).
- **Visualiza√ß√£o** de m√©tricas/comportamento aprendido.

---

## üì¶ Formato da entrega
- **Pasta do projeto** com:
  - C√≥digo-fonte.
  - `README.md` organizado:
    - Introdu√ß√£o.
    - Tecnologias/bibliotecas.
    - Algoritmos aplicados.
    - C√°lculos/f√≥rmulas.
    - Como executar (treinar/testar).
    - Resultados e coment√°rios finais.
- **Nome do projeto**:
  ```bash
  NomeDoMeuProjeto-<sua_matricula>-<seu_nome_ou_tema>
  ```

---

## üóìÔ∏è Prazos (corrigidos)
- **Janela oficial de entrega**: **14/10/2025 ‚Üí 21/11/2025 (sex, 23:59)**.

### Cronograma
- **21/10**: reposit√≥rio + **commit INIT** com README rascunho e cabe√ßalhos nos arquivos.
- **23/10**: tema definido + objetivos/algoritmos.
- **28/10**: baseline rodando; m√©tricas definidas.
- **04/11**: experimento 1 (Œµ‚Äëgreedy) + gr√°ficos iniciais.
- **11/11**: experimento 2 (tuning/abla√ß√£o) + tabelas. (INICIO DAS APRESENTA√á√ïES)
- **18/11**: *code freeze* + README final. (INICIO DAS APRESENTA√á√ïES)
- **At√© 21/11 23:59**: envio do link (GitHub/GitLab ou ZIP no Drive). (INICIO DAS APRESENTA√á√ïES)

---

## üõ†Ô∏è Commit inicial (obrigat√≥rio)
Inclui **configura√ß√£o inicial** e breve descri√ß√£o da ideia no `README.md`.

```bash
git init
git add .
git commit -m "ADS-init: <sua_matricula> ML"
git branch -M main
git remote add origin <URL_DO_REPO>
git push -u origin main
```

### Cabe√ßalho padr√£o em **todos os arquivos**
```py
"""
Nome do arquivo: <ex.: train_model.py>
Data de cria√ß√£o: 21/10/2025
Autor: <Seu Nome>
Matr√≠cula: <Sua Matr√≠cula>

Descri√ß√£o:
<objetivo do arquivo>
Funcionalidades:
- <ponto 1>
- <ponto 2>
"""
```

---

## üß± Estrutura sugerida
```text
.
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ envs/              # ambientes/MDPs
‚îÇ   ‚îú‚îÄ‚îÄ agents/            # QLearning/SARSA/modelos
‚îÇ   ‚îú‚îÄ‚îÄ utils/             # m√©tricas, plots, seed
‚îÇ   ‚îú‚îÄ‚îÄ train.py           # treino do agente/modelo
‚îÇ   ‚îî‚îÄ‚îÄ eval.py            # avalia√ß√£o e gera√ß√£o de gr√°ficos
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ configs/           # hiperpar√¢metros (YAML/JSON)
‚îÇ   ‚îî‚îÄ‚îÄ runs/              # logs, checkpoints, m√©tricas
‚îú‚îÄ‚îÄ results/               # figuras/tabelas finais
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## ‚ñ∂Ô∏è Como executar
### 1) Ambiente
```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/macOS:
source .venv/bin/activate
pip install -r requirements.txt
```

### 2) Treinar
```bash
python -m src.train --algo qlearning --episodes 2000 --env GridWorld-v0   --epsilon_start 1.0 --epsilon_min 0.05 --epsilon_decay 0.995   --alpha 0.1 --gamma 0.99 --seed 42 --out experiments/runs/run1
```

### 3) Avaliar e gerar gr√°ficos
```bash
python -m src.eval --run experiments/runs/run1 --episodes 200 --render false   --export results/
```

> **Reprodutibilidade**: fixe *seed*, salve hiperpar√¢metros e vers√µes de libs.

---

## üìä M√©tricas e visualiza√ß√µes
- Recompensa m√©dia/epis√≥dio (curva).
- Taxa de sucesso/epis√≥dio.
- Evolu√ß√£o de **Œµ (epsilon)** ao longo do treino.
- Heatmap da **Q‚ÄëTable** (ou curvas de perda/acc se supervisionado).
- Tabelas comparando abla√ß√µes (ex.: *alpha*, *gamma*, *epsilon_decay*).

---

## üßÆ Algoritmos e f√≥rmulas (exemplo Q‚ÄëLearning)
Atualiza√ß√£o Q:
\[
Q(s,a) \leftarrow Q(s,a) + \alpha \big[r + \gamma \max_{a'} Q(s',a') - Q(s,a)\big]
\]

Pol√≠tica Œµ‚Äëgreedy:
- Com prob. **Œµ**: escolhe a√ß√£o aleat√≥ria (explora√ß√£o).
- Com prob. **1‚ÄëŒµ**: escolhe \(\arg\max_a Q(s,a)\) (aproveitamento).
- **Decaimento**: \(\epsilon_t = \max(\epsilon_{\min}, \epsilon_0 \cdot d^t)\).

> Se usar outro algoritmo (SARSA, DQN, supervis√£o), documente a f√≥rmula equivalente.

---

## ‚úÖ Checklist de entrega
- [ ] C√≥digo completo e **execut√°vel**.
- [ ] **README** com ideia, passos de treino/teste, libs, algoritmos e **f√≥rmulas**.
- [ ] **Gr√°ficos/prints** no `results/`.
- [ ] Cabe√ßalho padr√£o em **todos os arquivos**.
- [ ] `requirements.txt` com vers√µes.
- [ ] Link do reposit√≥rio enviado **at√© 21/11/2025 23:59**.

---

## üîç Integridade acad√™mica
- Entregas sem entendimento claro podem ser **anuladas**.
- C√≥pia/pl√°gio ser√£o **zerados**.
- Uso de IA sem **adapta√ß√£o e explica√ß√£o** pode ser **desconsiderado**.
- Reaproveitamento de trabalhos anteriores: s√≥ com **aviso** e **adapta√ß√£o**.

---

## üìå Observa√ß√µes finais
- Mantenha o hist√≥rico de commits limpo.
- Documente **dificuldades** e **decis√µes** de design de *reward*/hiperpar√¢metros.
- Priorize clareza sobre tamanho do projeto.
